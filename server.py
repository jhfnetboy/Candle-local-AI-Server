#!/usr/bin/env python3
"""
MyDictionary TTS Server
æœ¬åœ° TTS æœåŠ¡å™¨,æ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢
"""

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import torch
import numpy as np
from transformers import AutoProcessor, AutoModel
import soundfile as sf
import io
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # å…è®¸ Chrome Extension è·¨åŸŸè®¿é—®

class TTSModelManager:
    """TTS æ¨¡å‹ç®¡ç†å™¨"""

    def __init__(self):
        self.models = {}
        self.processors = {}
        self.current_model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")

        # å¯ç”¨æ¨¡å‹é…ç½®
        self.available_models = {
            "speecht5": {
                "name": "SpeechT5 (English)",
                "model_id": "microsoft/speecht5_tts",
                "vocoder_id": "microsoft/speecht5_hifigan",
                "language": "en",
                "quality": 6,
                "speed": "fast"
            },
            "cosyvoice": {
                "name": "CosyVoice (ä¸­è‹±æ–‡)",
                "model_id": "FunAudioLLM/CosyVoice-300M",
                "language": "zh-en",
                "quality": 9,
                "speed": "medium"
            }
        }

    def load_model(self, model_key):
        """åŠ è½½æŒ‡å®šæ¨¡å‹"""
        if model_key in self.models:
            logger.info(f"âœ… æ¨¡å‹ {model_key} å·²åŠ è½½")
            self.current_model = model_key
            return True

        if model_key not in self.available_models:
            logger.error(f"âŒ æœªçŸ¥æ¨¡å‹: {model_key}")
            return False

        config = self.available_models[model_key]
        logger.info(f"ğŸ“¥ å¼€å§‹åŠ è½½æ¨¡å‹: {config['name']}")

        try:
            if model_key == "speecht5":
                # åŠ è½½ SpeechT5
                processor = AutoProcessor.from_pretrained(config["model_id"])
                model = AutoModel.from_pretrained(config["model_id"]).to(self.device)
                vocoder = AutoModel.from_pretrained(config["vocoder_id"]).to(self.device)

                self.models[model_key] = {"model": model, "vocoder": vocoder}
                self.processors[model_key] = processor

            elif model_key == "cosyvoice":
                # åŠ è½½ CosyVoice (éœ€è¦ç‰¹æ®Šå¤„ç†)
                # TODO: å®ç° CosyVoice åŠ è½½é€»è¾‘
                logger.warning("âš ï¸  CosyVoice æ”¯æŒå¼€å‘ä¸­...")
                return False

            self.current_model = model_key
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {config['name']}")
            return True

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def synthesize(self, text, **kwargs):
        """ç”Ÿæˆè¯­éŸ³"""
        if not self.current_model:
            raise ValueError("æ²¡æœ‰åŠ è½½çš„æ¨¡å‹")

        if self.current_model == "speecht5":
            return self._synthesize_speecht5(text, **kwargs)
        elif self.current_model == "cosyvoice":
            return self._synthesize_cosyvoice(text, **kwargs)

    def _synthesize_speecht5(self, text, speaker_id=0):
        """SpeechT5 åˆæˆ"""
        model_data = self.models["speecht5"]
        processor = self.processors["speecht5"]

        # å‡†å¤‡è¾“å…¥
        inputs = processor(text=text, return_tensors="pt").to(self.device)

        # åŠ è½½ speaker embeddings (ä½¿ç”¨é¢„è®¾çš„)
        # TODO: æ”¯æŒè‡ªå®šä¹‰ speaker embeddings
        embeddings_dataset = torch.load(
            "speaker_embeddings.pt",
            map_location=self.device
        ) if os.path.exists("speaker_embeddings.pt") else None

        if embeddings_dataset is None:
            # ä½¿ç”¨é»˜è®¤ embeddings
            speaker_embeddings = torch.zeros((1, 512)).to(self.device)
        else:
            speaker_embeddings = embeddings_dataset[speaker_id].unsqueeze(0)

        # ç”Ÿæˆè¯­éŸ³
        with torch.no_grad():
            speech = model_data["model"].generate_speech(
                inputs["input_ids"],
                speaker_embeddings,
                vocoder=model_data["vocoder"]
            )

        # è½¬æ¢ä¸º numpy array
        audio = speech.cpu().numpy()
        sample_rate = 16000

        return audio, sample_rate

    def _synthesize_cosyvoice(self, text, **kwargs):
        """CosyVoice åˆæˆ (TODO)"""
        raise NotImplementedError("CosyVoice æ”¯æŒå¼€å‘ä¸­")


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨
model_manager = TTSModelManager()

@app.route("/")
def index():
    """API ä¿¡æ¯"""
    return jsonify({
        "name": "MyDictionary TTS Server",
        "version": "1.0.0",
        "status": "running",
        "current_model": model_manager.current_model,
        "available_models": list(model_manager.available_models.keys())
    })

@app.route("/models", methods=["GET"])
def list_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    models_info = []
    for key, config in model_manager.available_models.items():
        models_info.append({
            "id": key,
            "name": config["name"],
            "language": config["language"],
            "quality": config["quality"],
            "speed": config["speed"],
            "loaded": key in model_manager.models,
            "current": key == model_manager.current_model
        })

    return jsonify({
        "success": True,
        "models": models_info
    })

@app.route("/models/<model_key>/load", methods=["POST"])
def load_model(model_key):
    """åŠ è½½æŒ‡å®šæ¨¡å‹"""
    success = model_manager.load_model(model_key)

    if success:
        return jsonify({
            "success": True,
            "message": f"æ¨¡å‹ {model_key} åŠ è½½æˆåŠŸ",
            "current_model": model_manager.current_model
        })
    else:
        return jsonify({
            "success": False,
            "error": f"æ¨¡å‹ {model_key} åŠ è½½å¤±è´¥"
        }), 500

@app.route("/synthesize", methods=["POST"])
def synthesize():
    """åˆæˆè¯­éŸ³"""
    data = request.get_json()

    if not data or "text" not in data:
        return jsonify({
            "success": False,
            "error": "ç¼ºå°‘ text å‚æ•°"
        }), 400

    text = data["text"]

    # å¯é€‰å‚æ•°
    speaker_id = data.get("speaker_id", 0)
    output_format = data.get("format", "wav")  # wav | mp3

    try:
        # ç”Ÿæˆè¯­éŸ³
        audio, sample_rate = model_manager.synthesize(
            text,
            speaker_id=speaker_id
        )

        # è½¬æ¢ä¸ºéŸ³é¢‘æ–‡ä»¶
        audio_buffer = io.BytesIO()
        sf.write(audio_buffer, audio, sample_rate, format=output_format)
        audio_buffer.seek(0)

        # è¿”å›éŸ³é¢‘æ–‡ä»¶
        return send_file(
            audio_buffer,
            mimetype=f"audio/{output_format}",
            as_attachment=True,
            download_name=f"tts.{output_format}"
        )

    except Exception as e:
        logger.error(f"âŒ åˆæˆå¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route("/health", methods=["GET"])
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "healthy",
        "device": model_manager.device,
        "models_loaded": len(model_manager.models),
        "current_model": model_manager.current_model
    })


if __name__ == "__main__":
    # é»˜è®¤åŠ è½½ SpeechT5
    logger.info("ğŸš€ å¯åŠ¨ TTS æœåŠ¡å™¨...")
    model_manager.load_model("speecht5")

    # å¯åŠ¨æœåŠ¡å™¨
    app.run(
        host="0.0.0.0",
        port=5050,
        debug=False
    )
